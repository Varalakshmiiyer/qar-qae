from keras.models import model_from_json
import os
import pandas as pd
import numpy as np
from common import read_json
from keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import *
import argparse

def extract_features(row, all_answers, image_caption, word_index, question_seq_length, caption_seq_length):
	x_questions = []
	x_captions = []

	for action in all_answers:
		if 'relevant' not in row:
			replacement_action = row['replacement_action']
		else:
			replacement_action = row['answer'].split(' ')[-1]

		new_question = row['question'].replace(replacement_action,action)
		question_feature = []
		caption_feature = []

		for word in new_question.split():
			if word in word_index:
				question_feature.append(word_index[word])
		x_questions.append(np.asarray(question_feature))

		for word in image_caption.split():
			if word in word_index:
				caption_feature.append(word_index[word])
		x_captions.append(np.asarray(caption_feature))

	x_questions = pad_sequences(x_questions, question_seq_length)
	x_captions = pad_sequences(x_captions, caption_seq_length)
	X = [np.asarray(x_captions), np.asarray(x_questions)]
	return X

def save_data(data, output_file):
	# print 'Data items: [%d]' % (len(data))
	df = pd.DataFrame(data)
	df.to_csv(output_file)
	return df

def get_best_predictions(y_predict, index_answer_relevant):
	predictions = []
	for y in y_predict:
		index = np.argmax(y)
		if (index_answer_relevant[index] == 1):
			predictions.append(y[index])
		else:
			predictions.append(0.0)
	return np.asarray(predictions)

def check_and_add_rank(rank, rank_list, y_predict_all, true_index, predicted_index):
	top = np.argpartition(y_predict_all, rank)[rank:]
	if true_index in top:
		rank_list.append(true_index)
	else:
		rank_list.append(predicted_index)

	return ','.join([all_answers[top_item] for top_item in top])

if __name__ == "__main__":
	parser = argparse.ArgumentParser()
	parser.add_argument('--base_dir', type=str, default='/sb-personal/cvqa/')
	parser.add_argument('--filter_rows', type=int, default=-1)
	parser.add_argument('--model_names', type=str, default='qc,qcatt,qclstm')

	args = parser.parse_args()
	base_dir = args.base_dir

	trials = range(0,10)
	output_dir = os.path.join(base_dir, 'data/visual-genome/8-26-2017/generated-data/')
	results_dir = os.path.join(base_dir, "results/c2vqa-verbs-results-final/")
	output_results_dir = os.path.join(base_dir, "results/c2vqa-verbs-results-relevance_as_edit/")
	questions_output_file = os.path.join(output_dir, 'editable_actions_vg_expanded_dataset-v2.csv')
	# questions_output_file = os.path.join(output_dir, 'normalized_editable_and_not_editable_actions_vg_expanded_dataset-v3.csv')
	word_index = read_json(os.path.join(results_dir, "word_to_index.json"))
	answer_index = read_json(os.path.join(results_dir, "answer_to_index.json"))
	caption_file = os.path.join(base_dir, 'data/cvqa/imagecaptions-vg.json')
	output_stats_file = os.path.join(output_results_dir, "stats.csv")
	model_names = args.model_names.split(',')
	filter_rows = args.filter_rows

	print "Loading Captions generated by a Pre-Trained Captioning Model for Images..."
	image_captions = read_json(caption_file)

	questions_df = pd.read_csv(questions_output_file)
	# questions_df = questions_df[questions_df['relevant'] == 0]
	all_image_files = questions_df['image_file'].unique().tolist()

	print "Removing question / images without captions..."
	all_image_files = [i for i in all_image_files if i in image_captions]

	all_image_files = set(all_image_files)

	questions_df = questions_df[questions_df['image_file'].isin(all_image_files)]
	all_answers = questions_df['answer'].unique().tolist()

	print 'All answers: [%d]' % (len(all_answers))

	index_answer_relevant = {} 
	for a in answer_index:
		index = answer_index[a]
		if a.startswith('relevant because'):
			index_answer_relevant[index] = 1
		else:
			index_answer_relevant[index] = 0

	stats = []
	for trial in trials:
		print 'Trial [%d]...' % (trial)

		used_image_files = all_image_files
		for model_name in model_names:
			test_output_results_file = os.path.join(results_dir, "%s-%d-test_results.csv" % (model_name, trial))
			test_results_df = pd.read_csv(test_output_results_file)
			used_image_files = used_image_files - set(test_results_df['image_file'].unique().tolist())
		
		filtered_df = questions_df[questions_df['image_file'].isin(used_image_files)]

		print 'Total rows: [%d]' % (len(filtered_df))
		print 'Total images: [%d]' % (len(used_image_files))
		if filter_rows > 0:
			filtered_df = filtered_df.sample(filter_rows)
		total = len(filtered_df)
		print 'Total rows filtered: [%d]' % (total)
		print 'Total images filtered: [%d]' % (len(filtered_df['image_file'].unique()))
		print 'Total answers filtered: [%d]' % (len(filtered_df['answer'].unique()))

		for model_name in model_names:
			print 'Model: [%s]' % (model_name)

			if model_name == 'qc':
				caption_seq_length = 16
				question_seq_length = 18
			else:
				caption_seq_length = 18
				question_seq_length = 18

			ckpt_model_weights_filename = os.path.join(results_dir, "%s-%d-model-best.h5" % (model_name, trial))
			rae_test_output_results_file = os.path.join(output_results_dir, "%s-%d-test_results.csv" % (model_name, trial))
			model_structure_filename = os.path.join(results_dir, "%s-model-structure.json" % (model_name))

			with open(model_structure_filename) as open_file:
				json_string = open_file.read()

			model = model_from_json(json_string)
			model.load_weights(ckpt_model_weights_filename)
			# print len(image_files)

			output_results = []
			y_true = []
			y_predict = []
			y_predict_3 = []
			y_predict_5 = []
			y_predict_10 = []

			i = 0
			for _,row in filtered_df.iterrows():
				# print row['original_question']
				if i % 1000 == 0:
					print '\tQuestion [%d/%d]' % (i,total)
				i+=1

				image_caption = image_captions[row['image_file']]

				X = extract_features(row, all_answers, image_caption, word_index, question_seq_length, caption_seq_length)
				# print '\tSamples [%d]' % (len(X[0]))
				y_predict_raw = model.predict(X)
				if model_name == 'qcatt':
					y_predict_raw = y_predict_raw[0]
				y_predict_all = get_best_predictions(y_predict_raw, index_answer_relevant)
				# print y_predict_all
				# print y_predict_all.shape
				predicted_index = np.argmax(y_predict_all)
				y_predict.append(predicted_index)
				true_index = all_answers.index(row['answer'])
				y_true.append(true_index)

				result = {}
				result['image_file'] = row['image_file']
				if 'original_question' in row:
					result['original_question'] = row['original_question']
				else:
					result['original_question'] = row['question']
				result['image_caption'] = image_caption
				result['y_predict_1'] = all_answers[predicted_index]

				result['y_predict_3'] = check_and_add_rank(-3, y_predict_3, y_predict_all, true_index, predicted_index)
				result['y_predict_5'] = check_and_add_rank(-5, y_predict_5, y_predict_all, true_index, predicted_index)
				result['y_predict_10'] = check_and_add_rank(-10, y_predict_10, y_predict_all, true_index, predicted_index)
				# top = np.argpartition(y_predict_all, -3)[-3:]
				# if true_index in top:
				# 	y_predict_3.append(true_index)
				# else:
				# 	y_predict_3.append(predicted_index)

				# result['y_predict_3'] = ','.join([all_answers[top_item] for top_item in top])

				# top = np.argpartition(y_predict_all, -5)[-5:]
				# if true_index in top:
				# 	y_predict_5.append(true_index)
				# else:
				# 	y_predict_5.append(predicted_index)

				# result['y_predict_5'] = ','.join([all_answers[top_item] for top_item in top])

				# top = np.argpartition(y_predict_all, -10)[-10:]
				# if true_index in top:
				# 	y_predict_10.append(true_index)
				# else:
				# 	y_predict_10.append(predicted_index)

				# result['y_predict_10'] = ','.join([all_answers[top_item] for top_item in top])

				result['y_true'] = row['answer']

				output_results.append(result)
			results_df = save_data(output_results, rae_test_output_results_file)
			# print results_df

			y_predict = np.asarray(y_predict)
			y_predict_3 = np.asarray(y_predict_3)
			y_predict_5 = np.asarray(y_predict_5)
			y_true = np.asarray(y_true)

			stat = {}
			stat['model_name'] = model_name
			stat['trial'] = trial
			stat['top_1_accuracy'] = accuracy_score(y_true, y_predict)
			stat['top_3_accuracy'] = accuracy_score(y_true, y_predict_3)
			stat['top_5_accuracy'] = accuracy_score(y_true, y_predict_5)
			stat['top_10_accuracy'] = accuracy_score(y_true, y_predict_10)
			stats.append(stat)

			print stat
			save_data(stats, output_stats_file)

	stats_df = save_data(stats, output_stats_file)
	print stats_df


# print model.summary()